{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT-Transformer(E-D).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWVEY2Ayn-04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c632c940-24fc-40fe-92e0-519d8d9775c6"
      },
      "source": [
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGXMWCz4oBvI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import math\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOhIpWdHoP8n"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg37sLJHoRn6"
      },
      "source": [
        "## **Read Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9z-DcdWUlWn"
      },
      "source": [
        "### **Create Pairs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYXHG7zyoDa-"
      },
      "source": [
        "def create_pairs(src_path, tgt_path):\n",
        "  print(\"Reading lines...\")\n",
        "\n",
        "  src = open(src_path).readlines()\n",
        "  tgt = open(tgt_path).readlines()\n",
        "\n",
        "  pairs = []\n",
        "  for i in range(len(src)):\n",
        "    pair = []\n",
        "    s = src[i].strip().strip('\\n')\n",
        "    t = tgt[i].strip().strip('\\n')\n",
        "    pair.append(s)\n",
        "    pair.append(t)\n",
        "    pairs.append(pair)\n",
        "  \n",
        "  return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD068OJPUoBw"
      },
      "source": [
        "### **Create Vocabulary**\n",
        "Create Data and Subword Tokenization by Byte Pair Encoding(BPE) using Sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZWredrnoFhS"
      },
      "source": [
        "def create_vocab(pairs):\n",
        "  src = [pair[0] for pair in pairs]\n",
        "  tgt = [pair[1] for pair in pairs]\n",
        "  with open(\"src.txt\", 'w') as f:\n",
        "    f.writelines(\"%s\\n\" % s for s in src)\n",
        "  with open(\"tgt.txt\", 'w') as f:\n",
        "    f.writelines(\"%s\\n\" % t for t in tgt)\n",
        "  \n",
        "  spm.SentencePieceTrainer.train('--input=src.txt --model_prefix=s --vocab_size=2000 --model_type=bpe --normalization_rule_name=nmt_nfkc_cf --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3')\n",
        "  spm.SentencePieceTrainer.train('--input=tgt.txt --model_prefix=t --vocab_size=2000 --model_type=bpe --normalization_rule_name=nmt_nfkc_cf --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3')\n",
        "\n",
        "  source_vocab = spm.SentencePieceProcessor()\n",
        "  target_vocab = spm.SentencePieceProcessor()\n",
        "\n",
        "  source_vocab.load('s.model')\n",
        "  target_vocab.load('t.model')\n",
        "\n",
        "  return source_vocab, target_vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW8xgwlJoKBi"
      },
      "source": [
        "def prepare_data(src_path, tgt_path):\n",
        "  pairs = create_pairs(src_path, tgt_path)\n",
        "\n",
        "  print(f\"Read {len(pairs)} sentence pairs\")\n",
        "\n",
        "  return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVwtiKnloLyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8d39c1-71e8-408f-b83e-29e38e51cee1"
      },
      "source": [
        "# Path to train files\n",
        "train_src_path = \"train.en\"\n",
        "train_tgt_path = \"train.mr\"\n",
        "\n",
        "# Path to valid files\n",
        "valid_src_path = \"tun.en\"\n",
        "valid_tgt_path = \"tun.mr\"\n",
        "\n",
        "# Path to test files\n",
        "test_src_path = \"test.en\"\n",
        "test_tgt_path = \"test.mr\"\n",
        "\n",
        "train_pairs = prepare_data(train_src_path, train_tgt_path)\n",
        "source_vocab, target_vocab = create_vocab(train_pairs) \n",
        "\n",
        "valid_pairs = prepare_data(valid_src_path, valid_tgt_path)\n",
        "\n",
        "test_pairs = prepare_data(test_src_path, test_tgt_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 46277 sentence pairs\n",
            "Reading lines...\n",
            "Read 500 sentence pairs\n",
            "Reading lines...\n",
            "Read 2000 sentence pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSlA3E_WWkMC"
      },
      "source": [
        "for i in train_pairs:\n",
        "  t = i[0].split(\" \")\n",
        "  if len(t) < 7:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GLDJG4vVJuX"
      },
      "source": [
        "### **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IeeQ9ooNrH"
      },
      "source": [
        "def source_tokenizer(sentence):\n",
        "  tokens = source_vocab.encode_as_ids(sentence)\n",
        "  tokens = [source_vocab.bos_id()] + tokens + [source_vocab.eos_id()]\n",
        "  return tokens\n",
        "\n",
        "def target_tokenizer(sentence):\n",
        "  tokens = target_vocab.encode_as_ids(sentence)\n",
        "  tokens = [target_vocab.bos_id()] + tokens + [target_vocab.eos_id()]\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPkq-UjJoVN0"
      },
      "source": [
        "## **Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw5_jZLsoeMq"
      },
      "source": [
        "def data_process(pairs):\n",
        "  data = []\n",
        "  for line in pairs:\n",
        "    src = torch.tensor(source_tokenizer(line[0]), dtype = torch.long)\n",
        "    tgt = torch.tensor(target_tokenizer(line[1]), dtype = torch.long)\n",
        "    if len(src) <= 100 and len(tgt) <= 100:\n",
        "      data.append((src, tgt))\n",
        "\n",
        "  return data\n",
        "\n",
        "train_data = data_process(train_pairs)\n",
        "valid_data = data_process(valid_pairs)\n",
        "test_data = data_process(test_pairs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6idic3Gsoe8v"
      },
      "source": [
        "PAD_IDX=target_vocab.pad_id()\n",
        "BATCH_SIZE=256\n",
        "def generate_batch(pairs):\n",
        "  src_batch, tgt_batch = [],[]\n",
        "  for (s,t) in pairs:\n",
        "    src_batch.append(s)\n",
        "    tgt_batch.append(t)\n",
        "\n",
        "  src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "  tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "\n",
        "  return src_batch, tgt_batch\n",
        "\n",
        "train_iter = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(valid_data, batch_size = BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbiCOSd7oiGh"
      },
      "source": [
        "# **Model Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TJftFw-onQa"
      },
      "source": [
        "## **Encoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1U5zDJSosb2"
      },
      "source": [
        "### **Encoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOhH31tJom4s"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, embed_size, src_vocab_size,\n",
        "               src_pad_idx,\n",
        "               nheads, nhid, nencl,\n",
        "               dropout, max_len, device):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "    self.src_word_embed = nn.Embedding(src_vocab_size, embed_size)\n",
        "    initrange = 0.1\n",
        "    self.src_word_embed.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    self.src_pos_enc = PositionalEncoding(embed_size, dropout, max_len)\n",
        "\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=nheads, dim_feedforward=nhid, dropout=dropout)\n",
        "    \n",
        "    encoder_norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.transformer_encoder = nn.TransformerEncoder(encoder_layer, nencl, encoder_norm)\n",
        "\n",
        "  def forward(self, src):\n",
        "    src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "    src = self.src_word_embed(src) * math.sqrt(self.embed_size)\n",
        "\n",
        "    src = self.src_pos_enc(src)\n",
        "\n",
        "    src = src.to(self.device)\n",
        "    src_mask = src_mask.to(self.device)\n",
        "\n",
        "    output = self.transformer_encoder(src, src_key_padding_mask=src_mask)\n",
        "\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw55y1ffBK-C"
      },
      "source": [
        "### **Positional Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JkawyTgrHqa"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4X5aJOxokCX"
      },
      "source": [
        "## **Decoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjoUfU0oArNE"
      },
      "source": [
        "### **Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJbuSSCIAtxc"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, embed_size, tgt_vocab_size, \n",
        "               tgt_pad_idx,\n",
        "               nheads, nhid, ndecl,\n",
        "               dropout, max_len, device):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embed_size = embed_size\n",
        "    self.device = device\n",
        "\n",
        "    self.tgt_word_embed = nn.Embedding(tgt_vocab_size, embed_size)\n",
        "    initrange = 0.1\n",
        "    self.tgt_word_embed.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    self.tgt_pos_enc = PositionalEncoding(embed_size, dropout, max_len)\n",
        "\n",
        "    decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=nheads, dim_feedforward=nhid, dropout=dropout)\n",
        "\n",
        "    decoder_norm = nn.LayerNorm(embed_size)\n",
        "\n",
        "    self.transformer_decoder = nn.TransformerDecoder(decoder_layer, ndecl, decoder_norm)\n",
        "\n",
        "  def forward(self, tgt, memory):\n",
        "    tgt_seq_len = tgt.size(0)\n",
        "\n",
        "    tgt = self.tgt_word_embed(tgt) * math.sqrt(self.embed_size)\n",
        "\n",
        "    tgt = self.tgt_pos_enc(tgt)\n",
        "    #print(\"tgt\")\n",
        "    #print(tgt)\n",
        "    mask = (torch.triu(torch.ones(tgt_seq_len, tgt_seq_len)) == 1).transpose(0, 1)\n",
        "    #tgt_mask = mask.float().masked_fill(mask==0, float('inf')).masked_fill(mask == 1, float(0.0))\n",
        "    tgt_mask = mask.masked_fill(mask==0, True).masked_fill(mask == 1, False)\n",
        "\n",
        "    tgt = tgt.to(device)\n",
        "    tgt_mask = tgt_mask.to(device)\n",
        "    #print(tgt_mask.shape)\n",
        "\n",
        "    output = self.transformer_decoder(tgt=tgt, memory=memory, tgt_mask = tgt_mask)\n",
        "    #print(\"output\")\n",
        "    #print(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG5J9SmGXMh8"
      },
      "source": [
        "## **Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmeoWjCYXUSL"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, embed_size, tgt_vocab_size,\n",
        "               encoder, decoder):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "    self.fc_out = nn.Linear(embed_size, tgt_vocab_size, bias = False)\n",
        "\n",
        "  def forward(self, src, tgt):\n",
        "    \n",
        "    encoder_output = self.encoder(src)\n",
        "    #print(\"encoder_output\")\n",
        "    #print(encoder_output)\n",
        "    decoder_output = self.decoder(tgt, encoder_output)\n",
        "    #print(\"decoder_output\")\n",
        "    #decoder_output = decoder_output.masked_fill(torch.isnan(decoder_output), 0)\n",
        "    #print(decoder_output)\n",
        "\n",
        "    output = self.fc_out(decoder_output)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQg7RERRaLk0"
      },
      "source": [
        "# **Making Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH6x1gRSaORz"
      },
      "source": [
        "# device\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Training Values\n",
        "num_epochs = 500\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Vocabulary Sizes\n",
        "src_vocab_size = 2000\n",
        "tgt_vocab_size = 2000\n",
        "\n",
        "# Transformer Values\n",
        "embed_size = 512\n",
        "nheads = 8\n",
        "nhid = 512\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.1\n",
        "MAX_LEN = 100\n",
        "warmup = 4000\n",
        "\n",
        "# Pad Indexes\n",
        "src_pad_idx = PAD_IDX\n",
        "tgt_pad_idx = PAD_IDX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7E3QgkmafFa"
      },
      "source": [
        "encoder = Encoder(embed_size, src_vocab_size,\n",
        "                  src_pad_idx,\n",
        "                  nheads, nhid, num_encoder_layers,\n",
        "                  dropout, MAX_LEN, device)\n",
        "\n",
        "decoder = Decoder(embed_size, tgt_vocab_size, \n",
        "                  tgt_pad_idx,\n",
        "                  nheads, nhid, num_decoder_layers,\n",
        "                  dropout, MAX_LEN, device)\n",
        "\n",
        "transformer = Transformer(embed_size, tgt_vocab_size,\n",
        "                          encoder, decoder)\n",
        "\n",
        "model = transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jTKce4y3CMc"
      },
      "source": [
        "for p in model.parameters():\n",
        "  if p.dim() > 1:\n",
        "    nn.init.xavier_uniform_(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Guubdset2i",
        "outputId": "43c65f6f-9308-4905-a3a7-a68e9c8bb6a0"
      },
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total number of Model Parameters: {total_params}\")\n",
        "print(f\"Total number of Model Parameters: {trainable_params}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of Model Parameters: 15696896\n",
            "Total number of Model Parameters: 15696896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIn6hrlAVTZS"
      },
      "source": [
        "## **Noam Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHHf3gyphCBK"
      },
      "source": [
        "class NoamOpt:\n",
        "    \"Optim wrapper that implements rate.\"\n",
        "    def __init__(self, model_size, factor, warmup, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self.warmup = warmup\n",
        "        self.factor = factor\n",
        "        self.model_size = model_size\n",
        "        self._rate = 0\n",
        "        \n",
        "    def step(self):\n",
        "        \"Update parameters and rate\"\n",
        "        self._step += 1\n",
        "        rate = self.rate()\n",
        "        for p in self.optimizer.param_groups:\n",
        "            p['lr'] = rate\n",
        "        self._rate = rate\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def rate(self, step = None):\n",
        "        \"Implement `lrate` above\"\n",
        "        if step is None:\n",
        "            step = self._step\n",
        "        return self.factor * \\\n",
        "            (self.model_size ** (-0.5) *\n",
        "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
        "        \n",
        "def get_std_opt(model):\n",
        "    return NoamOpt(embed_size, 2, 4000,\n",
        "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aU7cICKbIgv"
      },
      "source": [
        "model.to(device)\n",
        "\n",
        "optimizer = get_std_opt(model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itgNgeNEbnrP"
      },
      "source": [
        "# **Translation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgcKdxVbbPUX"
      },
      "source": [
        "def translate(model, sentence):\n",
        "  source = torch.tensor(source_tokenizer(sentence), dtype = torch.long)\n",
        "  if len(source) <= 100:\n",
        "    source = source.unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [target_vocab.bos_id()]\n",
        "\n",
        "    for i in range(MAX_LEN):\n",
        "      target = torch.tensor(outputs, dtype=torch.long).unsqueeze(1).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        output = model(source, target)\n",
        "        #print(output)\n",
        "      best_guess = output.argmax(2)[-1, :].item()\n",
        "      outputs.append(best_guess)\n",
        "      \n",
        "      if best_guess == target_vocab.eos_id():\n",
        "        break\n",
        "    print(outputs)\n",
        "    translated_sentence = target_vocab.decode_ids(outputs)\n",
        "  else:\n",
        "    translated_sentence = \"\"\n",
        "  return translated_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbmNdPFvjCR4",
        "outputId": "a97ecdd3-862e-4a26-8b65-55c8ff0b3982"
      },
      "source": [
        "sentence = \"Digestion becomes fast from walk\"\n",
        "model.eval()\n",
        "translated_sentence = translate(model, sentence)\n",
        "print(translated_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 815, 59, 187, 1279, 63, 1553, 1279, 1913, 1437, 1254, 148, 18, 279, 217, 187, 1279, 1913, 1437, 1254, 148, 47, 18, 279, 217, 1745, 1279, 1913, 1437, 1553, 1279, 1913, 1437, 1553, 1279, 1913, 1437, 1553, 1279, 1913, 1437, 1553, 1279, 1914, 1706, 1553, 1279, 1913, 1437, 1553, 1279, 1914, 1706, 1553, 1279, 1913, 1437, 1553, 1279, 1914, 1706, 561, 20, 3]\n",
            "फिरण्यापासून पचना लवकर पचनक्रिया तीव्र होते अक्रोडपासून पचनक्रिया तीव्र होते आणि अक्रोड वेगाने पचनक्रिया लवकर पचनक्रिया लवकर पचनक्रिया लवकर पचनक्रिया लवकर पचवढी लवकर पचनक्रिया लवकर पचवढी लवकर पचनक्रिया लवकर पचवढी येते .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWVVXzXzbrtz"
      },
      "source": [
        "# **Traning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ljBjQkvbS3E"
      },
      "source": [
        "sentence = \"Digestion becomes fast from walk\"\n",
        "total_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "  step=0\n",
        "  i=0\n",
        "  total_loss = 0\n",
        "\n",
        "  print(f\"Epoch {epoch} / {num_epochs}\")\n",
        "  '''\n",
        "  if save_model:\n",
        "    checkpoint = {\n",
        "        \"save_dict\" : model.save_dict(),\n",
        "        \"optimizer\" : optimizer.state_dict()\n",
        "    }\n",
        "\n",
        "  save_checkpoint(checkpoint)\n",
        "  '''\n",
        "  model.eval()\n",
        "  translated_sentence = translate(model, sentence)\n",
        "\n",
        "  print(translated_sentence)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (source, target) in enumerate(train_iter):\n",
        "    if batch_idx%200 == 1:\n",
        "      #print(total_loss)\n",
        "      #print(total_loss/batch_idx)\n",
        "      print(batch_idx)\n",
        "\n",
        "    source = source.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    # Forward\n",
        "    output = model(source, target[:-1])\n",
        "\n",
        "    output = output.reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "    i = i + target.shape[0]\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    total_loss = loss.item() + total_loss\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.optimizer.zero_grad()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "  print(total_loss)\n",
        "  print(total_loss/i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_fRV8aToxBT",
        "outputId": "4be376e9-7817-4d3e-fd90-69f3f12a72a7"
      },
      "source": [
        "a = torch.tensor([[1,2,3],[4,5,6]])\n",
        "a[:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gii3huLBbgYj"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7C8YSaabUqi"
      },
      "source": [
        "# Path to test files\n",
        "ref = open(\"test.mr\", 'r').readlines()\n",
        "src = open(\"test.en\", 'r').readlines()\n",
        "hyp = []\n",
        "refs = []\n",
        "for i in range(len(src)):\n",
        "  if i % 100 == 0:\n",
        "    print(i)\n",
        "  h = translate(model, src[i])\n",
        "  if h != \"\":\n",
        "    refs.append(ref[i])\n",
        "    hyp.append(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0QVPCMVbbtb"
      },
      "source": [
        "!pip3 install sacrebleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogt8VSAFbZZY"
      },
      "source": [
        "import sacrebleu\n",
        "bleu = sacrebleu.corpus_bleu(hyp, [ref])\n",
        "print(bleu.score)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}